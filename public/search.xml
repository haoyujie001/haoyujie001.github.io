<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>数据库知识点回顾总结（1）</title>
      <link href="/2020/04/09/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE%E6%80%BB%E7%BB%93(1)/"/>
      <url>/2020/04/09/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE%E6%80%BB%E7%BB%93(1)/</url>
      
        <content type="html"><![CDATA[<p>使用终端操作数据库</p><p>  如何登陆数据库?<br>mysql -uroot -p123456</p><p>1.如何查看有什么数据库?</p><p>show databases;</p><hr><pre><code>2.如何选择数据库?</code></pre><figure class="highlight plain"><figcaption><span>databasesName;```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* * *</span><br><span class="line"></span><br><span class="line">    3.如何查看该数据库中有哪些表?</span><br><span class="line">&#96;&#96;&#96;show tables;</span><br></pre></td></tr></table></figure><a id="more"></a><hr><pre><code>4.如何查询表中的数据?</code></pre><figure class="highlight plain"><figcaption><span>* from tableName;```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* * *</span><br><span class="line"></span><br><span class="line">    5.如何退出数据库服务器?</span><br><span class="line">&#96;&#96;&#96;exit;</span><br></pre></td></tr></table></figure><hr><pre><code>6.如何在数据库服务器中创建自己的数据库?</code></pre><p><code>create database databaseName;</code></p><hr><pre><code>7.如何创建一个数据表? 创建一个pet表</code></pre><p>create TABLE pet(<br>                   name VARCHAR(20),<br>                   owner VARCHAR(20),<br>                   specise VARCHAR(20),<br>                   sex CHAR(1),<br>                   brith DATAE,<br>                   death DATE );</p><pre><code>注意事项:</code></pre><p><strong>1</strong>:var()与varchar()的区别在于var()是定常的,哪怕存储的字符串没有达到”()”中数字的上限,var()依然会占用空格来填充空间.而varchar()则是不定长的,没有达到”()”中的上限则会自动去掉后面的空格;<br><strong>2</strong>:性别不要用:sex 要用:gender  一个是性 一个是性别;<br><strong>3</strong>:定义最后一个字段的时候不要加”,”;<br>  <strong>4</strong>:上面的”VAR”,”VARCHAR”,”DATE”可以用小写.不过最好用大写来表示区分关键字,若不然也许写到后面你自己都不知道这个词是数据库中的关键字还是你自己自定义的一些数据,同时一定要用英文的标点符号也必须半角输入</p><hr><pre><code>8.如何查看数据表的架构?</code></pre><p>describe tableName;<br> 说明:<br>+——-+————-+——+—–+———+——-+</p><p>| Field | Type        | Null | Key | Default | Extra |</p><p>+——-+————-+——+—–+———+——-+<br> Field    :    字段的名称<br>  Type     :    字段的类型,可以有int    var    varchar<br>  Key      :    是否是关键字 如可以定义为:  primary key 或者 unique key   …<br>Default: :    若是该字段没有主动设置值的时候,该字段的默认值是什么?</p><hr><pre><code>9.如何插入数据?</code></pre><p> INSERT INTO pet VALUES(‘kk’,’cc’,’dog’,’1’,’1998-8-2’,null);<br>           +——+——-+———+——+————+——-+<br>           | name | owner | specise | sex     | brith           | death |<br>           +——+——-+———+——+————+——-+<br>           | kk       | cc       | dog      | 1        | 1998-08-02 | NULL|<br>           +——+——-+———+——+————+——-+<br>       注意:<br>           NULL:代表的是空,表示该字段还没有数据.千万不要主动填写’NULL’,这代表你的字段有一个值叫做’null’.</p><pre><code>其实还有一种写法:</code></pre><p>INSERT INTO pet(name,owner) VALUES (‘xx’,’cc’);<br>代表我只在name和owner字段上面插入的一条,其他皆为NULL/默认值的数据</p><hr><pre><code>10.mysql 常用数据类型       注意:金钱最好用int/bigint(整数,单位用分,拿出来进行*100换成元),千万不要直接用浮点,会有精度损失.</code></pre><hr><pre><code>11.如何删除数据   先插入数据:   INSERT INTO pet VALUES(&apos;kk1&apos;,&apos;cc1&apos;,&apos;dog1&apos;,&apos;1&apos;,&apos;1998-1-2&apos;,null);   INSERT INTO pet VALUES(&apos;kk2&apos;,&apos;cc2&apos;,&apos;dog2&apos;,&apos;2&apos;,&apos;1998-2-2&apos;,null);   INSERT INTO pet VALUES(&apos;kk3&apos;,&apos;cc3&apos;,&apos;dog3&apos;,&apos;1&apos;,&apos;1998-3-2&apos;,&apos;1998-12-2&apos;);   INSERT INTO pet VALUES(&apos;kk4&apos;,&apos;cc4&apos;,&apos;dog4&apos;,&apos;2&apos;,&apos;1998-4-2&apos;,null);   删除语句:</code></pre><p>DELETE FROM tablesName WHRER 条件;</p><pre><code>修改数据:</code></pre><p>UPDATE tableName SET 字段1=值1,字段2=值2 … WHERE 条件;</p><hr><p>总结:1.table的操作 2.表操作的总结</p><hr><p>12.mysql建表中的约束<br><strong>1.主键约束:</strong><br>它能够<strong>唯一确定</strong>一张表中的一条记录,增加主键约束之后,就可以使得字段不重复而且不为空<br>create table user(<br>    id int PRIMARY KEY,<br>    name VARCHAR(20)<br>);<br>INSERT INTO user VALUES (1,’张三’);</p><p>+—-+——+<br>| id | name |<br>+—-+——+<br>|  1 | 张三 |<br>+—-+——+</p><p>运行DESCRIBE user;<br>+——-+————-+——+—–+———+——-+<br>| Field | Type        | Null | Key | Default | Extra |<br>+——-+————-+——+—–+———+——-+<br>| id    | int(11)     | NO   | PRI | NULL    |       |<br>| name  | varchar(20) | YES  |     | NULL    |       |<br>+——-+————-+——+—–+———+——-+<br>发现 id是不可以为null 而且 key的值 也变为:PRI(primary)</p><p><strong>2.复合主键(联合主键）:</strong><br>CREATE TABLE user2(    id INT,    name VARCHAR(20),    password VARCHAR(20),    PRIMARY key(id,name));运行DESCRIBE user2;+———-+————-+——+—–+———+——-+| Field    | Type        | Null | Key | Default | Extra |+———-+————-+——+—–+———+——-+| id       | int(11)     | NO   | PRI | NULL    |       || name     | varchar(20) | NO   | PRI | NULL    |       || password | varchar(20) | YES  |     | NULL    |       |+———-+————-+——+—–+———+——-+INSERT INTO user2 VALUES (1,’老王’,’123456’);INSERT INTO user2 VALUES (2,’老王’,’123456’);+—-+——+———-+| id | name | password |+—-+——+———-+|  1 | 老王 | 123456   ||  2 | 老王 | 123456   |+—-+——+———-+<br>说明了复合主键只要所有的字段都不是相同的情况下可以允许其中的字段重复:</p><p>INSERT INTO user2 VALUES (1,’老李’,’123456’);</p><p>SELECT * FROM user2;<br>+—-+——+———-+<br>| id | name | password |<br>+—-+——+———-+<br>|  1 | 老李 | 123456   |<br>|  1 | 老王 | 123456   |<br>|  2 | 老王 | 123456   |<br>+—-+——+———-+<br>场景:表中有班级号以及学生座位号,我们可以用班级号+学生的座位号可以准确的定位一个学生,如:(1班5号可以准确的确定一个学生)</p><pre><code>**3.自增约束:**</code></pre><p>CREATE TABLE user3(<br>    id INT PRIMARY KEY AUTO_INCREMENT,<br>    name VARCHAR(20)<br>);</p><p>运行DESCRIBE user3;<br>+——-+————-+——+—–+———+—————-+<br>| Field | Type        | Null | Key | Default | Extra          |<br>+——-+————-+——+—–+———+—————-+<br>| id    | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name  | varchar(20) | YES  |     | NULL    |                |<br>+——-+————-+——+—–+———+—————-+</p><p>INSERT INTO user3(name) VALUES(‘张三’);<br>INSERT INTO user3(name) VALUES(‘李四’);<br>+—-+——+<br>| id | name |<br>+—-+——+<br>|  1 | 张三 |<br>|  2 | 李四 |<br>+—-+——+<br>没有自定义id值 但是自动生成了id<br><strong>4.唯一约束:</strong><br>CREATE TABLE user5(<br>    id INT PRIMARY KEY AUTO_INCREMENT,<br>    name VARCHAR(20)<br>);<br>运行 DESCRIBE user5;<br>+——-+————-+——+—–+———+—————-+<br>| Field | Type        | Null | Key | Default | Extra          |<br>+——-+————-+——+—–+———+—————-+<br>| id    | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name  | varchar(20) | YES  |     | NULL    |                |<br>+——-+————-+——+—–+———+—————-+</p><p>新增name为唯一约束:<br>ALTER TABLE user5 ADD UNIQUE(name);<br>运行 DESCRIBE user5;<br>+——-+————-+——+—–+———+—————-+<br>| Field | Type        | Null | Key | Default | Extra          |<br>+——-+————-+——+—–+———+—————-+<br>| id    | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name  | varchar(20) | YES  | UNI | NULL    |                |<br>+——-+————-+——+—–+———+—————-+<br>测试:插入数据<br>INSERT INTO user5(name) VALUES (‘cc’);<br>运行 SELECT * FROM user5; 查看结果:<br>+—-+——+<br>| id | name |<br>+—-+——+<br>|  1 | cc   |<br>+—-+——+<br>再次插入INSERT INTO user5(name) VALUES (‘cc’);<br>出现:ERROR 1062 (23000): Duplicate entry ‘cc’ for key ‘name’</p><p>换个试试 INSERT INTO user5(name) VALUES (‘aa’);<br>运行 SELECT * FROM user5; 查看结果:<br>+—-+——+<br>| id | name |<br>+—-+——+<br>|  3 | aa   |<br>|  1 | cc   |<br>+—-+——+<br>总结一下:<br>    主键约束(primary key)中包含了唯一约束<br>场景:业务需求:设计一张用户注册表,用户姓名必须要用手机号来注册,而且手机号和用户名称都不能为空,那么:<br>CREATE TABLE user_test(<br>    id INT PRIMARY KEY AUTO_INCREMENT COMMENT’主键id’,<br>    name VARCHAR(20) NOT NULL COMMENT’用户姓名,不能为空’,<br>    phone_number VARCHAR(20) UNIQUE NOT NULL COMMENT’用户手机,不能重复且不能为空’<br>);<br>运行 DESCRIBE user_test;<br>+————–+————-+——+—–+———+—————-+<br>| Field        | Type        | Null | Key | Default | Extra          |<br>+————–+————-+——+—–+———+—————-+<br>| id           | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name         | varchar(20) | NO   |     | NULL    |                |<br>| phone_number | int(11)     | NO   | UNI | NULL    |                |<br>+————–+————-+——+—–+———+—————-+<br>这样的话就达到了每一个手机号都只能出现一次,达到了每个手机号只能被注册一次.<br>用户姓名可以重复,但是手机号码却不能重复,复合正常的逻辑需求</p><p><strong>5.非空约束:</strong><br>           在上面的表中已经添加了非空约束: NOT NULL;<br>name和phone_number都设置了非空,先只设置name参数不设置phone_number参数试一试<br>INSERT INTO user_test (name) VALUES (‘张三’);<br>会出现Field ‘phone_number’ doesn’t have a default value</p><p>两个非空参数一起设置:<br>INSERT INTO user_test (name,phone_number) VALUES (‘张三’,’12345678901’);<br>+—-+——+————–+<br>| id | name | phone_number |<br>+—-+——+————–+<br>|  1 | 张三 | 12345678901  |<br>+—-+——+————–+</p><p><strong>6.默认约束</strong><br>CREATE TABLE user6(<br>   id int PRIMARY KEY AUTO_INCREMENT COMMENT’主键id’,<br>    name VARCHAR(20) NOT NULL COMMENT’用户姓名不能为空’,<br>    phone_number VARCHAR(20) NOT NULL COMMENT’用户手机号,不能为空’,<br>    status INT DEFAULT 0 COMMENT’用户状态0:启用 1:禁封 默认:0’<br>);<br>运行DESCRIBE user6;<br>+————–+————-+——+—–+———+—————-+<br>| Field        | Type        | Null | Key | Default | Extra          |<br>+————–+————-+——+—–+———+—————-+<br>| id           | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name         | varchar(20) | NO   |     | NULL    |                |<br>| phone_number | varchar(20) | NO   |     | NULL    |                |<br>| status       | int(11)     | YES  |     | 0       |                |<br>+————–+————-+——+—–+———+—————-+<br>插入数据:<br>INSERT INTO user6(name,phone_number) VALUES (‘aa’,’123’);<br>INSERT INTO user6(name,phone_number) VALUES(‘bb’,’1234’);<br>INSERT INTO user6(name,phone_number) VALUES(‘cc’,’1263456’);</p><p>查看数据:SELECT * FROM user6;<br>+—-+——+————–+——–+<br>| id | name | phone_number | status |<br>+—-+——+————–+——–+<br>|  1 | aa   | 123          |      0 |<br>|  2 | bb   | 1234         |      0 |<br>|  3 | cc   | 1263456      |      0 |<br>+—-+——+————–+——–+<br>我们没有设置status的值,但是给我们创建了默认值 0.</p><p>应用场景:<br>业务需求:找正常的用户,对这些正常用户进行发放优惠卷或者积分之类的东西,而被禁封的用户我们不让其参加多动.<br>我们想要封用户只要将status的值从0改为1就行了,当然我们取用户的时候必须要先判断status是否是0.若是1.说明该用户已经被禁封.<br>先封手机号为’1234’的用户:<br>UPDATE user6 SET status = 1 WHERE phone_number= ‘1234’;<br>SELECT * FROM user6;<br>+—-+——+————–+——–+<br>| id | name | phone_number | status |<br>+—-+——+————–+——–+<br>|  1 | aa   | 123          |      0 |<br>|  2 | bb   | 1234         |      1 |<br>|  3 | cc   | 1263456      |      0 |<br>+—-+——+————–+——–+<br>status为1,说明用户已经被封,该用户不可以参加活动</p><p>我们取用户的时候加上status的判断,如:<br>SELECT * FROM user6 WHERE status = 0;<br>+—-+——+————–+——–+<br>| id | name | phone_number | status |<br>+—-+——+————–+——–+<br>|  1 | aa   | 123          |      0 |<br>|  3 | cc   | 1263456      |      0 |<br>+—-+——+————–+——–+</p><p><strong>7.外键约束</strong><br>CREATE TABLE classes(<br>    id INT PRIMARY KEY AUTO_INCREMENT COMMENT’班级表id’,<br>    name VARCHAR(20) COMMENT’班级名称’<br>);<br>运行DESCRIBE classes;<br>+——-+————-+——+—–+———+—————-+<br>| Field | Type        | Null | Key | Default | Extra          |<br>+——-+————-+——+—–+———+—————-+<br>| id    | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name  | varchar(20) | YES  |     | NULL    |                |<br>+——-+————-+——+—–+———+—————-+</p><p>CREATE TABLE student(<br>   id INT PRIMARY KEY AUTO_INCREMENT COMMENT’学生表id’,<br>   name VARCHAR(20) COMMENT’学生姓名’,<br>    class_id int COMMENT’教室id,这张表中的class_id是classes表中id的值’,<br>    FOREIGN KEY (class_id) REFERENCES classes(id)<br>);<br>//FOREIGN :外来  REFERENCES:应用,参考<br>运行DESCRIBE student;<br>+———-+————-+——+—–+———+—————-+<br>| Field    | Type        | Null | Key | Default | Extra          |<br>+———-+————-+——+—–+———+—————-+<br>| id       | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name     | varchar(20) | YES  |     | NULL    |                |<br>| class_id | int(11)     | YES  | MUL | NULL    |                |<br>+———-+————-+——+—–+———+—————-+</p><p>班级插入数据:<br>INSERT INTO CLASSES (name) VALUES (‘一班’);<br>INSERT INTO CLASSES (name) VALUES (‘二班’);<br>INSERT INTO CLASSES (name) VALUES (‘三班’);<br>INSERT INTO CLASSES (name) VALUES (‘四班’);<br>查看数据 SELECT * FROM classes;<br>+—-+——+<br>| id | name |<br>+—-+——+<br>|  1 | 一班 |<br>|  2 | 二班 |<br>|  3 | 三班 |<br>|  4 | 四班 |<br>+—-+——+</p><p>学生插入数据:<br>INSERT INTO student (name,class_id) VALUES (‘小赵’,1);<br>INSERT INTO student (name,class_id) VALUES (‘小钱’,2);<br>INSERT INTO student (name,class_id) VALUES (‘小孙’,3);<br>INSERT INTO student (name,class_id) VALUES (‘小李’,4);<br>查看数据 SELECT * FROM student;<br>+—-+——+———-+<br>| id | name | class_id |<br>+—-+——+———-+<br>|  1 | 小赵 |        1 |<br>|  2 | 小钱 |        2 |<br>|  3 | 小孙 |        3 |<br>|  4 | 小李 |        4 |<br>+—-+——+———-+<br>若是像插入班级为5的数据 如:<br>INSERT INTO student (name,class_id) VALUES (‘小周’,5);<br>报错: Cannot add or update a child row</p><p>我们删除正在被学生表引用的’四班’试试:<br>DELETE classes WHERE name = ‘四班’;<br>出现:Cannot delete or update a parent row:不能删除主表中的行</p><p>我们先删除学生表中的 ‘小李’从而解除班级中’四班’的外键约束,再来删除’四班’(因为小李引用了四班)<br>DELETE FROM student WHERE name = ‘小李’;<br>再次删除classes表中的’四班’;<br>DELETE FROM classes WHERE name = ‘四班’;<br>最后: SELECT * FROM classes;<br>+—-+——+<br>| id | name |<br>+—-+——+<br>|  1 | 一班 |<br>|  2 | 二班 |<br>|  3 | 三班 |<br>+—-+——+<br>‘四班’被成功删除!</p><p>总结:<br>1.主表中没有的数据,在附表中,是不可以使用的.<br>2.主表中记录的数据现在正在被附表所引用,那么主表中正在被引用的数据不可以被删除<br>3.若要想删除,先将附表中的数据删除在删除主表数据<br>4.对于外键约束大家可以联想 省,市 来进行联想 (市必须要依赖于省,只要省还有一个市在引用,那么就不可以删除省,要不然市就没有省了. 那么我们想删除省,必须要将该省下所有的市全部删除之后,才可以删除这个省)</p><p><strong>8.如何建表之后添加主键约束</strong><br>CREATE TABLE user4(<br>    id INT,<br>    name VARCHAR(20)<br>);<br>运行DESCRIBE user4;<br>+——-+————-+——+—–+———+——-+<br>| Field | Type        | Null | Key | Default | Extra |<br>+——-+————-+——+—–+———+——-+<br>| id    | int(11)     | YES  |     | NULL    |       |<br>| name  | varchar(20) | YES  |     | NULL    |       |<br>+——-+————-+——+—–+———+——-+</p><p>加入主键约束:<br>ALTER TABLE user4 add PRIMARY KEY(id);<br>再次运行DESCRIBE user4;<br>+——-+————-+——+—–+———+——-+<br>| Field | Type        | Null | Key | Default | Extra |<br>+——-+————-+——+—–+———+——-+<br>| id    | int(11)     | NO   | PRI | NULL    |       |<br>| name  | varchar(20) | YES  |     | NULL    |       |<br>+——-+————-+——+—–+———+——-+</p><p>删除主键约束:<br>ALERT TABLE user4 DROP PRIMARY KEY;<br>运行DESCRIBE user4查看表结构:<br>+——-+————-+——+—–+———+——-+<br>| Field | Type        | Null | Key | Default | Extra |<br>+——-+————-+——+—–+———+——-+<br>| id    | int(11)     | NO   |     | NULL    |       |<br>| name  | varchar(20) | YES  |     | NULL    |       |<br>+——-+————-+——+—–+———+——-+</p><p>使用modify 修改字段.添加约束:<br>ALTER TABLE user4 MODIFY id INT PRIMARY key;<br>使用DESCRIBE user4 查看表结构:<br>+——-+————-+——+—–+———+——-+<br>| Field | Type        | Null | Key | Default | Extra |<br>+——-+————-+——+—–+———+——-+<br>| id    | int(11)     | NO   | PRI | NULL    |       |<br>| name  | varchar(20) | YES  |     | NULL    |       |<br>+——-+————-+——+—–+———+——-+</p><p>给主键设置自增长:<br>ALTER TABLE user4 MODIFY id INT AUTO_INCREMENT;<br>运行 DESCRIBE user4 查看表结构:<br>+——-+————-+——+—–+———+—————-+<br>| Field | Type        | Null | Key | Default | Extra          |<br>+——-+————-+——+—–+———+—————-+<br>| id    | int(11)     | NO   | PRI | NULL    | auto_increment |<br>| name  | varchar(20) | YES  |     | NULL    |                |<br>+——-+————-+——+—–+———+—————-+</p><p>9.三大范式<br>1.数据表中的所有字段都是不可分割的原子值。<br>2必须满足第一范式下，除主键外的每一列都必须完全依赖于主键。<br> 如果要出现不完全依赖，只可能出现在联合主键的情况下。<br>3 必须先满足第二范式，除开主键列的其他列之间不能有传递依赖关系</p><p>合起来就是   在每列不能拆分的情况下，每列（除主键）必须依赖主键且只依赖于主键</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop的安装与配置</title>
      <link href="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="大数据开发技术："><a href="#大数据开发技术：" class="headerlink" title="大数据开发技术："></a>大数据开发技术：</h1><h1 id="一、-安装、配置VM虚拟机软件，安装Centos7"><a href="#一、-安装、配置VM虚拟机软件，安装Centos7" class="headerlink" title="一、 安装、配置VM虚拟机软件，安装Centos7"></a>一、 安装、配置VM虚拟机软件，安装Centos7</h1><h3 id="1、安装虚拟机软件VMware"><a href="#1、安装虚拟机软件VMware" class="headerlink" title="1、安装虚拟机软件VMware"></a>1、安装虚拟机软件VMware</h3><ol><li>安装<a id="more"></a></li></ol><p>打开F:\bigdata\soft\VMware12.rar，</p><p>运行VMware-workstation_full_12.1.1.6932.exe 进入安装界面，点击【下一步】</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image001.png" alt></p><ol><li>选择“我接受许可协议中的条款”，点击【下一步】</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image002.png" alt></p><ol><li>选择“增强型键盘驱动程序”，点击【下一步】</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image003.png" alt></p><ol><li>点击【下一步】</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image004.png" alt></p><ol><li><p>继续【下一步】<br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image005.png" alt></p></li><li><p>点击【安装】<br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image006.png" alt></p></li><li><p>等待安装完成</p></li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image007.png" alt></p><ol><li><p>点击【许可证】<br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image008.png" alt></p></li><li><p>输入密钥：5A02H-AU243-TZJ49-GTC7K-3C61N，并点击【输入】</p></li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image009.png" alt></p><ol><li>安装完成，点击【完成】</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image010.png" alt></p><ol><li>运行VMware<br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image012.png" alt></li><li>验证安装是否成功</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image014.png" alt></p><h3 id="2、配置网络IP和网关"><a href="#2、配置网络IP和网关" class="headerlink" title="2、配置网络IP和网关"></a>2、配置网络IP和网关</h3><h4 id="查看虚拟网络编辑器"><a href="#查看虚拟网络编辑器" class="headerlink" title="查看虚拟网络编辑器"></a>查看虚拟网络编辑器</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image016.png" alt></p><h4 id="修改ip地址"><a href="#修改ip地址" class="headerlink" title="修改ip地址"></a>修改ip地址</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image018.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image020.png" alt></p><h4 id="设置虚拟网卡VMnet8的网址"><a href="#设置虚拟网卡VMnet8的网址" class="headerlink" title="设置虚拟网卡VMnet8的网址"></a>设置虚拟网卡VMnet8的网址</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image022.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image024.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image026.png" alt></p><h3 id="3、加载已有的虚拟机"><a href="#3、加载已有的虚拟机" class="headerlink" title="3、加载已有的虚拟机"></a>3、加载已有的虚拟机</h3><p>选择文件——&gt;打开</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image028.png" alt></p><p>选择F:\Virtual Machines\hadoop01\hadoop01.vmx</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image030.png" alt><br>虚拟机文件即完成加载，点击启动即可。</p><h3 id="4、新建虚拟机"><a href="#4、新建虚拟机" class="headerlink" title="4、新建虚拟机"></a>4、新建虚拟机</h3><h4 id="新建虚拟机向导"><a href="#新建虚拟机向导" class="headerlink" title="新建虚拟机向导"></a>新建虚拟机向导</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image032.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image034.png" alt></p><h4 id="创建虚拟空白光盘"><a href="#创建虚拟空白光盘" class="headerlink" title="创建虚拟空白光盘"></a>创建虚拟空白光盘</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image036.png" alt></p><h4 id="安装Linux系统对应的CentOS版"><a href="#安装Linux系统对应的CentOS版" class="headerlink" title="安装Linux系统对应的CentOS版"></a>安装Linux系统对应的CentOS版</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image038.png" alt></p><h4 id="虚拟机命名和定位磁盘位置"><a href="#虚拟机命名和定位磁盘位置" class="headerlink" title="虚拟机命名和定位磁盘位置"></a>虚拟机命名和定位磁盘位置</h4><p>一定注意安装在F:\Virtual Machines目录下，这样可以在下一次上课时重复使用。</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image040.png" alt></p><h4 id="处理器配置"><a href="#处理器配置" class="headerlink" title="处理器配置"></a>处理器配置</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image042.png" alt></p><h4 id="设置内存为2GB"><a href="#设置内存为2GB" class="headerlink" title="设置内存为2GB"></a>设置内存为2GB</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image044.png" alt></p><h4 id="选择网络类型"><a href="#选择网络类型" class="headerlink" title="选择网络类型"></a>选择网络类型</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image046.png" alt></p><h4 id="选择控制器类型"><a href="#选择控制器类型" class="headerlink" title="选择控制器类型"></a>选择控制器类型</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image048.png" alt></p><h4 id="选择磁盘类型"><a href="#选择磁盘类型" class="headerlink" title="选择磁盘类型"></a>选择磁盘类型</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image050.png" alt></p><h4 id="新建虚拟磁盘"><a href="#新建虚拟磁盘" class="headerlink" title="新建虚拟磁盘"></a>新建虚拟磁盘</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image052.png" alt></p><h4 id="设置磁盘容量"><a href="#设置磁盘容量" class="headerlink" title="设置磁盘容量"></a>设置磁盘容量</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image054.png" alt></p><h4 id="指定磁盘文件"><a href="#指定磁盘文件" class="headerlink" title="指定磁盘文件"></a>指定磁盘文件</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image056.png" alt></p><h4 id="新建虚拟机向导配置完成"><a href="#新建虚拟机向导配置完成" class="headerlink" title="新建虚拟机向导配置完成"></a>新建虚拟机向导配置完成</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image058.png" alt></p><h4 id="VM设置"><a href="#VM设置" class="headerlink" title="VM设置"></a>VM设置</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image060.png" alt></p><h4 id="加载ISO"><a href="#加载ISO" class="headerlink" title="加载ISO"></a>加载ISO</h4><p>选择F:/bigdata/soft/CentOS-7-x86_64-DVD-1511.iso，选择启动时连接和已连接</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image062.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image064.png" alt></p><h3 id="5、安装CentOS7"><a href="#5、安装CentOS7" class="headerlink" title="5、安装CentOS7"></a>5、安装CentOS7</h3><blockquote><p>  使用Ctrl+Alt可以实现Windows主机和VM之间窗口的切换</p></blockquote><h4 id="开启并安装CentOS7"><a href="#开启并安装CentOS7" class="headerlink" title="开启并安装CentOS7"></a>开启并安装CentOS7</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image066.png" alt></p><p>回车继续</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image068.png" alt></p><p>ESC跳过磁盘检测</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image070.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image072.png" alt></p><h4 id="开启后初始化欢迎进入页面，选择中文——-gt-简体中文"><a href="#开启后初始化欢迎进入页面，选择中文——-gt-简体中文" class="headerlink" title="开启后初始化欢迎进入页面，选择中文——&gt;简体中文"></a>开启后初始化欢迎进入页面，选择中文——&gt;简体中文</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image74.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image76.png" alt></p><ol><li>单击软件选择（S）</li></ol><p>选择最小化安装，然后点击左上角&lt;完成&gt;按钮</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image78.png" alt></p><ol><li>安装位置，默认，点击&lt;完成&gt;</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image080.png" alt></p><h4 id="开始安装，配置root密码"><a href="#开始安装，配置root密码" class="headerlink" title="开始安装，配置root密码"></a>开始安装，配置root密码</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image082.png" alt></p><p>输入两次hadoop后点击两次完成按钮。</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image084.png" alt></p><h4 id="安装完成后重启Centos7"><a href="#安装完成后重启Centos7" class="headerlink" title="安装完成后重启Centos7"></a>安装完成后重启Centos7</h4><p>进入命令行界面输入用户名和密码</p><p>#root</p><p>#hadoop</p><h1 id="二：-练习使用VI编辑器，学习Linux的配置"><a href="#二：-练习使用VI编辑器，学习Linux的配置" class="headerlink" title="二： 练习使用VI编辑器，学习Linux的配置"></a>二： 练习使用VI编辑器，学习Linux的配置</h1><h3 id="1-、VI-VIM编辑器"><a href="#1-、VI-VIM编辑器" class="headerlink" title="1 、VI/VIM编辑器"></a>1 、VI/VIM编辑器</h3><h4 id="一般模式"><a href="#一般模式" class="headerlink" title="一般模式"></a>一般模式</h4><p>以 vi 打开一个档案就直接进入一般模式了(这是默认的模式)。在这个模式中，<br>你可以使用『上下左右』按键来移动光标，你可以使用『删除字符』或『删除整行』来处理档案内容，<br>也可以使用『复制、粘贴』来处理你的文件数据。</p><p><strong>常用语法</strong></p><blockquote><p>  1）yy （功能描述：复制光标当前一行）</p></blockquote><blockquote><p>  y数字y （功能描述：复制一段(从第几行到第几行)）</p></blockquote><blockquote><p>  2）p （功能描述：箭头移动到目的行粘贴）</p></blockquote><blockquote><p>  3）u （功能描述：撤销上一步）</p></blockquote><blockquote><p>  4）dd （功能描述：删除光标当前行）</p></blockquote><blockquote><p>  d数字d （功能描述：删除光标(含)后多少行）</p></blockquote><blockquote><p>  5）x （功能描述：删除一个字母，相当于del）</p></blockquote><blockquote><p>  X （功能描述：删除一个字母，相当于Backspace）</p></blockquote><blockquote><p>  6）yw （功能描述：复制一个词）</p></blockquote><blockquote><p>  7）dw （功能描述：删除一个词）</p></blockquote><blockquote><p>  8）shift+^ （功能描述：移动到行头）</p></blockquote><blockquote><p>  9）shift+$ （功能描述：移动到行尾）</p></blockquote><blockquote><p>  10）1+shift+g （功能描述：移动到页头，数字）</p></blockquote><blockquote><p>  11）shift+g （功能描述：移动到页尾）</p></blockquote><blockquote><p>  12）数字N+shift+g （功能描述：移动到目标行）</p></blockquote><h4 id="编辑模式"><a href="#编辑模式" class="headerlink" title="编辑模式"></a>编辑模式</h4><p>在一般模式中可以进行删除、复制、粘贴等等的动作，但是却无法编辑文件内容的！<br>要等到你按下『i, I, o, O, a, A, r, R』等任何一个字母之后才会进入编辑模式。</p><p>注意了！通常在 Linux 中，按下这些按键时，在画面的左下方会出现『INSERT 或 REPLACE<br>』的字样，此时才可以进行编辑。而如果要回到一般模式时，<br>则必须要按下『Esc』这个按键即可退出编辑模式。</p><p><strong>常用语法</strong></p><blockquote><p>  1）进入编辑模式</p></blockquote><blockquote><p>  （1）i 当前光标前</p></blockquote><blockquote><p>  （2）a 当前光标后</p></blockquote><blockquote><p>  （3）o 当前光标行的下一行</p></blockquote><blockquote><p>  2）退出编辑模式</p></blockquote><blockquote><p>  按『Esc』键</p></blockquote><ol><li>指令模式</li></ol><p>在一般模式当中，输入『 : /<br>?』3个中的任何一个按钮，就可以将光标移动到最底下那一行。</p><p>在这个模式当中， 可以提供你『搜寻资料』的动作，而读取、存盘、大量取代字符、离开<br>vi 、显示行号等动作是在此模式中达成的！</p><p><strong>常用语法</strong></p><blockquote><p>  1）基本语法</p></blockquote><blockquote><p>  （1）: 选项</p></blockquote><blockquote><p>  选项：</p></blockquote><blockquote><p>  w 保存</p></blockquote><blockquote><p>  q 退出</p></blockquote><blockquote><p>  ！ 感叹号强制执行</p></blockquote><blockquote><p>  （2）/ 查找，/被查找词，n是查找下一个，shift+n是往上查找</p></blockquote><blockquote><p>  （3）? 查找，?被查找词，n是查找上一个，shift+n是往下查找</p></blockquote><blockquote><p>  2）案例</p></blockquote><blockquote><p>  :wq! 强制保存退出</p></blockquote><h3 id="2、系统管理配置"><a href="#2、系统管理配置" class="headerlink" title="2、系统管理配置"></a>2、系统管理配置</h3><h4 id="修改linux主机名hostname文件"><a href="#修改linux主机名hostname文件" class="headerlink" title="修改linux主机名hostname文件"></a>修改linux主机名hostname文件</h4><blockquote><p>  （1）修改主机名，通过编辑/etc/hostname文件</p></blockquote><p>#vi /etc/hostname</p><blockquote><p>  输入hadoop01</p></blockquote><blockquote><p>  保存退出。</p></blockquote><blockquote><p>  注意：删除文件原有的内容，主机名称不要有“_”下划线，主机名修改后重启才能生效。</p></blockquote><blockquote><p>  （2）重启后可以查看本机的主机名。通过hostname命令查看</p></blockquote><p>#hostname</p><blockquote><p>  Hadoop01</p></blockquote><h4 id="修改Linux的hosts文件，建立主机名与IP地址的关联。"><a href="#修改Linux的hosts文件，建立主机名与IP地址的关联。" class="headerlink" title="修改Linux的hosts文件，建立主机名与IP地址的关联。"></a>修改Linux的hosts文件，建立主机名与IP地址的关联。</h4><p>#vi /etc/hosts</p><p>添加如下内容</p><blockquote><p>  172.16.248.201 hadoop01</p></blockquote><blockquote><p>  修改hostname不用重启设备，直接生效。</p></blockquote><h4 id="修改window7系统的的hosts文件，打开文件资源管理器"><a href="#修改window7系统的的hosts文件，打开文件资源管理器" class="headerlink" title="修改window7系统的的hosts文件，打开文件资源管理器"></a>修改window7系统的的hosts文件，打开文件资源管理器</h4><p>（1）进入C:\Windows\System32\drivers\etc目录</p><p>（2）打开hosts文件并追加如下内容，保存退出。</p><blockquote><p>  172.16.248.201 hadoop01</p></blockquote><h4 id="修改Linux的IP地址"><a href="#修改Linux的IP地址" class="headerlink" title="修改Linux的IP地址"></a>修改Linux的IP地址</h4><p>修改IP地址，红字部分每台机器有可能不同，打开/etc/sysconfig/network-scripts目录下查看。</p><p>#vi /etc/sysconfig/network-scripts/ifcfg-ens33</p><p>需要修改的内容有5项，前两项修改，后三项添加，然后保存退出。注意等号前是变量名要大写。</p><blockquote><p>  ONBOOT=yes</p></blockquote><blockquote><p>  BOOTPROTO=static</p></blockquote><blockquote><p>  IPADDR=172.16.248.201</p></blockquote><blockquote><p>  NETMASK=255.255.255.0</p></blockquote><blockquote><p>  GATEWAY=172.16.248.1</p></blockquote><blockquote><p>  注意：DNS1=210.43.0.8</p></blockquote><p>修改完成后重启网络服务</p><p>#systemctl restart network.service</p><p>验证是否成功</p><p>从windows的启动菜单点击最下方的“搜索程序和文件”框运行，输入<br>cmd，回车。输入以下命令：</p><p>C:\&gt;ping hadoop01</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image086.png" alt></p><blockquote><p>  为成功，不成功如下：</p></blockquote><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image088.png" alt></p><p>不同的操作系统提示格式可能不同，注意看提示的信息内容。</p><h4 id="Linux的防火墙"><a href="#Linux的防火墙" class="headerlink" title="Linux的防火墙"></a>Linux的防火墙</h4><p>1）基本语法：</p><p>#systemctl status firewalld</p><p>或</p><p>#firewall-cmd –state</p><p>关闭防火墙</p><p>#systemctl stop firewalld</p><p>关闭防火墙开机启动</p><p>#systemctl disable firewalld</p><h4 id="安装包文件"><a href="#安装包文件" class="headerlink" title="安装包文件"></a>安装包文件</h4><p>挂载光驱：</p><p>首先确定在vmware虚拟机设置中光驱是否连接</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image090.png" alt><br>创建光驱目录</p><p># mkdir /mnt/cdrom</p><p>挂载光驱</p><p># mount /dev/sr0 /mnt/cdrom</p><p>查看光盘目录</p><p># ls /mnt/cdrom</p><p>进入安装包目录</p><p># cd /mnt/cdrom/Packages/</p><p>安装lrzsz-0.12.20-36.el7.x86_64.rpm</p><p># rpm -ivf lrzsz-0.12.20-36.el7.x86_64.rpm</p><p>安装tree-1.6.0-10.el7.x86_64.rpm</p><p># rpm -ivf tree-1.6.0-10.el7.x86_64.rpm</p><h4 id="关机重启Linux"><a href="#关机重启Linux" class="headerlink" title="关机重启Linux"></a>关机重启Linux</h4><p>在linux领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机<br>。</p><p>正确的关机流程为：sync &gt; shutdown &gt; reboot &gt; halt</p><ol><li>基本语法：</li></ol><p>（1）sync   （功能描述：将数据由内存同步到硬盘中）</p><p>（2）shutdown [选项] 时间</p><p>选项：</p><p>-h：关机</p><p>-r：重启</p><p>（3）halt （功能描述：关闭系统，等同于shutdown –h now 和 poweroff）</p><p>（4）reboot （功能描述：就是重启，等同于 shutdown –r now）</p><ol><li>案例</li></ol><p>（1）将数据由内存同步到硬盘中</p><p>#sync  </p><p>（2）计算机将在10分钟后关机，并且会显示在登录用户的当前屏幕中</p><p>#shutdown –h 10</p><blockquote><p>  ‘This server will shutdown after 10 mins’</p></blockquote><p>（3）立马关机</p><p># shutdown –h now</p><p>（4）系统立马重启</p><p># shutdown –r now</p><p>（5）重启（等同于 shutdown –r now）</p><p># reboot</p><p>（6）关机（等同于shutdown –h now 和 poweroff）</p><p>#halt</p><h1 id="三：-securtCRT的安装配置和使用"><a href="#三：-securtCRT的安装配置和使用" class="headerlink" title="三： securtCRT的安装配置和使用"></a>三： securtCRT的安装配置和使用</h1><h3 id="1、安装SecureCRT"><a href="#1、安装SecureCRT" class="headerlink" title="1、安装SecureCRT"></a>1、安装SecureCRT</h3><p>Linux系统中是通过SSH服务实现的远程登录功能，默认ssh服务端口号为<br>22。Window系统上Linux远程登录客户端有SecureCRT, Shell,XShell等。</p><ol><li><p>安装步骤</p><ol><li>启动scrt_sfx704-x64.exe</li></ol></li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image092.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image094.png" alt></p><ol start="2"><li>一直Next即可，安装完成后关闭。</li></ol><h4 id="注册（一定要先关闭secureCRT软件才能注册成功，win10系统要用管理员运行以下软件）"><a href="#注册（一定要先关闭secureCRT软件才能注册成功，win10系统要用管理员运行以下软件）" class="headerlink" title="注册（一定要先关闭secureCRT软件才能注册成功，win10系统要用管理员运行以下软件）"></a>注册（一定要先关闭secureCRT软件才能注册成功，win10系统要用管理员运行以下软件）</h4><ol><li>运行F:\bigdata\soft\secureCRT注册机\SecureCrt.v.7.0注册机及注册方法\SecureCrt.v.7.0-kg.exe</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image096.png" alt></p><ol><li>点击patch，选择C:\Program Files\VanDyke<br>Software\Clients\SecureCRT.exe，打开，（记得要打开两次哦！）</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image098.png" alt></p><ol><li>点击打开，打开后确定（记得要打开两次哦！注册完成后要注意最后的提示是否成功，如果失败重新运行注册。如果还是不行，卸载secureCRT软件，重新安装）</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image100.png" alt></p><ol><li>打开桌面上SecureCRT 7.0或启动菜单下SecureCRT 7.0并运行</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image102.png" alt></p><ol><li><p>选择OK，现则Enter License Date<br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image104.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image106.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image108.png" alt></p></li><li><p>从注册机相对应的用户名等复制粘贴到SecureCRT中</p></li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image110.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image112.png" alt></p><ol><li>依次复制粘贴对应的内容</li></ol><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image114.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image116.png" alt><br>只有完成按钮出现注册即为成功。</p><h4 id="建立连接"><a href="#建立连接" class="headerlink" title="建立连接"></a>建立连接</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image118.png" alt></p><p>输入要连接的Linux主机名Hostname，Linux主机的用户名username，点击Connect（连接Linux主机）。</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image120.png" alt></p><p>输入该用户名的密码，选择Save<br>password（保存密码，下次直接登录，不用每次都输入密码）。</p><h4 id="快捷操作"><a href="#快捷操作" class="headerlink" title="快捷操作"></a>快捷操作</h4><p>鼠标选中即为复制，鼠标右键即为粘贴。</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image122.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image124.png" alt></p><ol><li><p>SecureCRT中文乱码解决方法</p><ol><li>调整设置CRT解决<br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image126.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image128.png" alt></li></ol></li></ol><h4 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h4><p>1）ctrl + c：停止进程</p><p>2）ctrl + l：清屏</p><p>3）ctrl + q：退出</p><p>4）善于用tab键</p><p>5）上下键：查找执行过的命令</p><p>6）ctrl + alt：linux和Windows之间切换</p><h1 id="四：-练习Linux的常用命令"><a href="#四：-练习Linux的常用命令" class="headerlink" title="四： 练习Linux的常用命令"></a>四： 练习Linux的常用命令</h1><h3 id="1、目录结构"><a href="#1、目录结构" class="headerlink" title="1、目录结构"></a>1、目录结构</h3><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image130.png" alt><br>树状目录结构</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image132.png" alt><br>/bin：是Binary的缩写，这个目录存放着系统必备执行命令</p><p>/boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件，自己的安装别放这里</p><p>/dev：Device(设备)的缩写，该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。</p><p>/etc：所有的系统管理所需要的配置文件和子目录。</p><p>/home：存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。</p><p>/lib：系统开机所需要最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。</p><p>/lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。</p><p>/media：linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。</p><p>/misc:<br>该目录可以用来存放杂项文件或目录，即那些用途或含义不明确的文件或目录可以存放在该目录下。</p><p>/mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。</p><p>/net 存放着和网络相关的一些文件.</p><p>/opt：这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。</p><p>/proc：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。</p><p>/root：该目录为系统管理员，也称作超级权限者的用户主目录。</p><p>/sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。</p><p>/selinux：这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙</p><p>/srv：service缩写，该目录存放一些服务启动之后需要提取的数据。</p><p>/sys：<br>这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统<br>sysfs 。</p><p>/tmp：这个目录是用来存放一些临时文件的。</p><p>/usr：<br>这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program<br>files目录。我们的Hadoop和java安装在这个目录下。</p><p>/var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。</p><h3 id="2、Linux常用命令"><a href="#2、Linux常用命令" class="headerlink" title="2、Linux常用命令"></a>2、Linux常用命令</h3><h4 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h4><ol><li>man 获得帮助信息</li></ol><p>#man ls</p><ol><li>help 获得shell内置命令的帮助信息</li></ol><p>#help cd</p><h4 id="文件目录类命令"><a href="#文件目录类命令" class="headerlink" title="文件目录类命令"></a>文件目录类命令</h4><ol><li>pwd 显示当前工作目录的绝对路径</li></ol><p>#pwd</p><ol><li>ls 列出目录的内容</li></ol><p>选项：</p><blockquote><p>  -a ：全部的文件，连同隐藏档( 开头为 . 的文件) 一起列出来(常用)</p></blockquote><blockquote><p>  -l ：长数据串列出，包含文件的属性与权限等等数据；(常用)</p></blockquote><p>每行列出的信息依次是： 文件类型与权限 链接数 文件属主 文件属组<br>文件大小用byte来表示 建立或最近修改的时间 名字</p><p># ls -al</p><ol><li>mkdir 创建一个新的目录</li></ol><p>mkdir [-p] 要创建的目录</p><p>#mkdir test</p><p>#mkdir -p user/root</p><ol><li>rmdir 删除一个空的目录</li></ol><p>#mkdir test</p><p>#rmdir test</p><ol><li>touch 创建空文件</li></ol><p>#touch test.java</p><ol><li>cd 切换目录</li></ol><p>（1）cd 绝对路径</p><p>（2）cd 相对路径</p><p>（3）cd ~或者cd （功能描述：回到自己的家目录）</p><p>（4）cd - （功能描述：回到上一次所在目录）</p><p>（5）cd .. （功能描述：回到当前目录的上一级目录）</p><blockquote><p>  使用绝对路径切换到root目录</p></blockquote><p>#cd /root</p><blockquote><p>  使用相对路径切换到root目录</p></blockquote><p>#cd ./root/</p><blockquote><p>  表示回到自己的家目录，亦即是 /root 这个目录</p></blockquote><p>#cd ~</p><blockquote><p>  cd- 回到上一次所在目录</p></blockquote><p>#cd -</p><blockquote><p>  表示回到当前目录的上一级目录，亦即是 /root 的上一级目录的意思；</p></blockquote><p>#cd ..</p><ol><li>cp 复制文件或目录</li></ol><p>复制文件</p><p>#cp test.java test</p><p>递归复制整个文件夹</p><p>#cp -r test test1</p><ol><li>移除文件或目录</li></ol><ul><li>删除空目录</li></ul><p>#rmdir test</p><ul><li>递归删除目录中所有内容</li></ul><p>#rm -rf test1</p><ol><li>mv 移动文件与目录或重命名</li></ol><ul><li>重命名</li></ul><p>#mv test.java test1.java</p><ul><li>移动文件或目录</li></ul><p>#mv test1.java test1</p><ol><li>cat 查看文件内容</li></ol><p># cat test.txt</p><ol><li>more 查看文件内容</li></ol><p>查看文件内容，一页一页的显示文件内容。</p><p>#more test1.java</p><ol><li>less 查看文件内容</li></ol><p>less 的作用与 more 十分相似，都可以用来浏览文字档案的内容，不同的是 less<br>允许使用[pageup] [pagedown]往回滚动。</p><p>#less test1.java</p><ol><li>echo 命令</li></ol><p>echo $SHELL</p><ol><li>history查看所敲命令历史</li></ol><p>#history</p><h4 id="时间日期类命令"><a href="#时间日期类命令" class="headerlink" title="时间日期类命令"></a>时间日期类命令</h4><ol><li>4.5.3.1 date显示当前时间</li></ol><p>#date</p><ol><li><p>date设置系统时间</p><ul><li>基本语法：</li></ul></li></ol><p>date -s 字符串时间</p><p>#date -s “2019-10-19 10:52:18”</p><h4 id="用户管理类命令"><a href="#用户管理类命令" class="headerlink" title="用户管理类命令"></a>用户管理类命令</h4><ol><li>useradd 添加新用户</li></ol><p>#user hadoop</p><ol><li>passwd 设置用户密码</li></ol><p>#passwd hadoop</p><ol><li>id 判断用户是否存在</li></ol><p>#id hadoop</p><ol><li>su 切换用户</li></ol><p>#su hadoop</p><ol><li>userdel 删除用户</li></ol><p>（1）删除用户但保存用户主目录</p><p>#userdel hadoop</p><p>（2）删除用户和用户主目录，都删除</p><p>#userdel –r hadoop</p><ol><li>who 查看登录用户信息</li></ol><p>1）基本语法</p><p>（1）whoami （功能描述：显示自身用户名称）</p><p>（2）who am i （功能描述：显示登录用户的用户名）</p><p>（3）who （功能描述：看当前有哪些用户登录到了本台机器上）</p><ol><li>tar解压</li></ol><p>tar打包</p><p>1）基本语法：</p><p>tar+参数+XXX.tar.gz+将要打包进去的内容</p><p>（功能描述：打包目录，压缩后的文件格式.tar.gz）</p><p>参数：</p><blockquote><p>  -c 产生.tar打包文件</p></blockquote><blockquote><p>  -v 显示详细信息</p></blockquote><blockquote><p>  -f 指定压缩后的文件名</p></blockquote><blockquote><p>  -z 打包同时压缩</p></blockquote><blockquote><p>  -x 解包.tar文件</p></blockquote><p>2）案例</p><p>（1）压缩：tar -zcvf XXX.tar.gz n1.txt n2.txt</p><p>压缩多个文件</p><p>#tar -zcvf test.tar.gz test1.java test.java</p><blockquote><p>  压缩目录</p></blockquote><p>#tar -zcvf test.java.tar.gz test1</p><p>（2）解压：tar -zxvf XXX.tar.gz</p><p>解压到当前目录</p><p>#tar -zxvf test.tar.gz</p><blockquote><p>  解压到/opt目录</p></blockquote><p>#tar -zxvf test.tar.gz –C /opt</p><h1 id="五：-在Linux系统安装java环境，克隆linux主机"><a href="#五：-在Linux系统安装java环境，克隆linux主机" class="headerlink" title="五： 在Linux系统安装java环境，克隆linux主机"></a>五： 在Linux系统安装java环境，克隆linux主机</h1><h3 id="1、安装JDK"><a href="#1、安装JDK" class="headerlink" title="1、安装JDK"></a>1、安装JDK</h3><ol><li>首先在secureCRT登录远程主机，进入要复制的目标目录，</li></ol><p>#cd /usr/local</p><p>用在windows的文件资源管理器用鼠标把jdk安装包jdk-8u191-linux-x64.tar.gz拖入到usr/local目录下。</p><ol><li>在linux系统下的/usr/local目录中查看软件包是否导入成功。</li></ol><p>#ls</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image134.png" alt></p><ol><li>解压jdk到/usr/local目录下</li></ol><p>#tar -zxvf jdk-8u191-linux-x64.tar.gz -C /usr/local</p><p>查看是否解压成功</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image136.png" alt><br>将目录改名为java</p><p>#mv /usr/local/jdk1.8.0_191 /usr/local/java</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image138.png" alt></p><ol><li><p>配置jdk环境变量</p><ol><li>先获取jdk路径：</li></ol></li></ol><p>#pwd</p><p>/usr/local/java</p><ol><li>打开/etc/profile文件：</li></ol><p>#vi /etc/profile</p><ol><li>在profile文件末尾添加jdk路径：</li></ol><p>export JAVA_HOME=/usr/local/java</p><p>export PATH=$PATH:$JAVA_HOME/bin</p><p>保存后退出：</p><ol><li>让修改后的文件生效：</li></ol><p>#source /etc/profile</p><ol><li>重启（如果java –version可以用就不用重启）：</li></ol><p>#sync</p><p>#reboot</p><ol><li>测试jdk安装成功</li></ol><p>#java -version</p><p>java version “1.8.0_191”</p><h3 id="2、克隆hadoop01，配置免密登录"><a href="#2、克隆hadoop01，配置免密登录" class="headerlink" title="2、克隆hadoop01，配置免密登录"></a>2、克隆hadoop01，配置免密登录</h3><h4 id="克隆虚拟机hadoop02"><a href="#克隆虚拟机hadoop02" class="headerlink" title="克隆虚拟机hadoop02"></a>克隆虚拟机hadoop02</h4><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image140.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image142.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image144.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image146.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image148.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image150.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image152.png" alt></p><h4 id="修改ip地址（配置新克隆的hadoop02和hadoop03）"><a href="#修改ip地址（配置新克隆的hadoop02和hadoop03）" class="headerlink" title="修改ip地址（配置新克隆的hadoop02和hadoop03）"></a>修改ip地址（配置新克隆的hadoop02和hadoop03）</h4><p>启动已经克隆的hadoop02，用root用户登录，然后修改网卡配置文件。</p><p>#vi /etc/sysconfig/network-scripts/ifcfg-ens33</p><p>找到以下行，红字部分不一样，删除UUID这一行，因为每张网卡的mac地址是不一样的，所以UUID也是不一样的。</p><p>UUID=c1ed5ea3-5e63-4295-835f-c4ae9e28dcb6</p><p>修改IPADDR的值，Hadoop02的ip是172.16.248.202，hadoop03的ip是172.16.248.203</p><p>IPADDR=172.16.248.102</p><h4 id="修改主机名称（配置新克隆的主机）"><a href="#修改主机名称（配置新克隆的主机）" class="headerlink" title="修改主机名称（配置新克隆的主机）"></a>修改主机名称（配置新克隆的主机）</h4><p># vi /etc/hostname</p><p>修改为：</p><p>hadoop02</p><h4 id="重启网络服务"><a href="#重启网络服务" class="headerlink" title="重启网络服务"></a>重启网络服务</h4><p># systemctl restart network.service</p><p>重复以上2）、3）和4）步修改hadoop03主机的IP地址和主机名。注意：，把以上hadoop02修改hadoop03。</p><h4 id="修改linux主机的hosts（hadoop01、hadoop02、hadoop03都需要配置）"><a href="#修改linux主机的hosts（hadoop01、hadoop02、hadoop03都需要配置）" class="headerlink" title="修改linux主机的hosts（hadoop01、hadoop02、hadoop03都需要配置）"></a>修改linux主机的hosts（hadoop01、hadoop02、hadoop03都需要配置）</h4><blockquote><p>  依次在hadoop01、hadoop02、hadoop03打开/etc/hosts</p></blockquote><p>vi /etc/hosts</p><blockquote><p>  添加如下内容</p></blockquote><blockquote><p>  172.16.248.201 hadoop01</p></blockquote><blockquote><p>  172.16.248.202 hadoop02</p></blockquote><blockquote><p>  172.16.248.203 hadoop03</p></blockquote><h4 id="修改window7的hosts文件"><a href="#修改window7的hosts文件" class="headerlink" title="修改window7的hosts文件"></a>修改window7的hosts文件</h4><p>（1）进入C:\Windows\System32\drivers\etc路径</p><p>（2）打开hosts文件并添加如下内容</p><blockquote><p>  172.16.248.201 hadoop01</p></blockquote><blockquote><p>  172.16.248.202 hadoop02</p></blockquote><blockquote><p>  172.16.248.203 hadoop03</p></blockquote><h1 id="六：-配置Linux三台服务器免密登录"><a href="#六：-配置Linux三台服务器免密登录" class="headerlink" title="六： 配置Linux三台服务器免密登录"></a>六： 配置Linux三台服务器免密登录</h1><h3 id="1、生成ssh免登陆密钥"><a href="#1、生成ssh免登陆密钥" class="headerlink" title="1、生成ssh免登陆密钥"></a>1、生成ssh免登陆密钥</h3><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image154.png" alt></p><p>#ssh-keygen -t rsa</p><p>（四个回车）执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>将公钥拷贝到要免密登陆的目标机器上</p><p>#ssh-copy-id hadoop01</p><p>#ssh-copy-id hadoop02</p><p>#ssh-copy-id hadoop03</p><p>过程中要求输入密码</p><p>验证是否成功登录hadoop02和hadoop03</p><p>#ssh hadoop02</p><p>#exit</p><p>#ssh hadoop03</p><p>#exit</p><p>自行练习登录远程主机执行远程主机的命令，并返回本机。大家可以试试在hadoop02上能不能免密登录到hadoop03，为什么？</p><h3 id="2、scp命令"><a href="#2、scp命令" class="headerlink" title="2、scp命令"></a>2、scp命令</h3><p>scp 是 secure copy 的缩写, scp 是 linux 系统下基于 ssh<br>登陆进行安全的远程文件拷贝命令。</p><p>从本地复制到远程</p><p>scp local_file remote_username@:remote_file</p><p>在Hadoop上建立一个文件test.txt，然后复制到hadoop02的/usr/local目录下或<br>hadoop03的/usr/local/下。</p><p>#touch test.txt</p><p>#scp test.txt hadoop2:/usr/local/</p><p>复制目录命令格式：</p><p>scp -r local_folder remote_ip:remote_folder</p><p>从远程复制到本地</p><p>从远程复制到本地，只要将从本地复制到远程的命令的后2个参数调换顺序即可，如下实例</p><p>自行练习复制目录到远程主机，并从远程主机复制文件到本地。</p><h3 id="3、centos7关闭linux服务器的图形界面："><a href="#3、centos7关闭linux服务器的图形界面：" class="headerlink" title="3、centos7关闭linux服务器的图形界面："></a>3、centos7关闭linux服务器的图形界面：</h3><p>multi-user.target: analogous to runlevel 3 #命令行模式</p><p>graphical.target: analogous to runlevel 5 #图形模式</p><p>查看当前默认启动</p><p>#systemctl get-default</p><p>#systemctl set-default multi-user.target</p><p>重启Linux</p><p>#reboot</p><h1 id="七：-安装和配置Hadoop2-7-1"><a href="#七：-安装和配置Hadoop2-7-1" class="headerlink" title="七： 安装和配置Hadoop2.7.1"></a>七： 安装和配置Hadoop2.7.1</h1><h3 id="1、集群简介"><a href="#1、集群简介" class="headerlink" title="1、集群简介"></a>1、集群简介</h3><p>HADOOP集群具体来说包含两个集群：HDFS集群和YARN集群，两者逻辑上分离，但物理上常在一起</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image156.png" alt></p><p>HDFS集群：</p><p>负责海量数据的存储，集群中的角色主要有 NameNode 、 DataNode</p><p>YARN集群：</p><p>负责海量数据运算时的资源调度，集群中的角色主要有 ResourceManager 、NodeManager</p><p>本集群搭建案例，以3节点为例进行搭建，角色分配如下：</p><table><thead><tr><th>hadoop01 NameNode、SecondaryNameNode、DataNode、ResourceManager、NodeManager hadoop02 DataNode NodeManager hadoop03 DataNode NodeManager</th></tr></thead></table><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image158.png" alt></p><h3 id="2、安装Hadoop"><a href="#2、安装Hadoop" class="headerlink" title="2、安装Hadoop"></a>2、安装Hadoop</h3><p>先上传hadoop的安装包到linux服务器Hadoop的/usr/local/目录下，用鼠标拖拽到指定的目录。</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image160.png" alt></p><h4 id="解压安装，配置路径"><a href="#解压安装，配置路径" class="headerlink" title="解压安装，配置路径"></a>解压安装，配置路径</h4><p>#tar -zxvf hadoop-2.7.1.tar.gz</p><p>#mv hadoop-2.7.1 hadoop</p><p>#vi /etc/profile</p><p>添加下行：</p><p>export HADOOP_HOME=/usr/local/hadoop</p><p>修改下行为：</p><p>PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</p><p>保存退出。执行source使之生效。</p><p>#source /etc/profile</p><h4 id="配置hadoop"><a href="#配置hadoop" class="headerlink" title="配置hadoop"></a>配置hadoop</h4><p>Hadoop的配置文件目录在/usr/local/hadoop/etc/hadoop/下</p><p>如果配置伪分布式环境（即只安装1台服务器），只需要修改前5个配置文件，无需执行第七步的分发。</p><p>#cd /usr/local/hadoop/etc/hadoop/</p><p>第一步：hadoop-env.sh</p><p>#vi hadoop-env.sh</p><p>第27行，修改为</p><p>export JAVA_HOME=/usr/local/java</p><p>第二步：core-site.xml</p><p>&lt;!– 指定HADOOP所使用的文件系统schema（URI），HDFS的老大（NameNode）的地址 –&gt;</p><p>#vi core-site.xml</p><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;fs.defaultFS&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><p>&lt;!– 指定hadoop运行时产生文件的存储目录 –&gt;</p><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><p>第三步：hdfs-site.xml</p><p>#vi hdfs-site.xml</p><p>&lt;!– 指定HDFS副本的数量 –&gt;</p><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;dfs.replication&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;3&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;hadoop01:50090&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;file:/usr/local/hadoop/data/namenode&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;file:/usr/local/hadoop/data/datanode&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><p>第四步：mapred-site.xml ，首先复制模板文件为xml文件</p><p>#cp mapred-site.xml.template mapred-site.xml</p><p>#vi mapred-site.xml</p><p>&lt;!– 指定mr运行在yarn上 –&gt;</p><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;yarn&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><p>第五步：yarn-site.xml</p><p>#vi yarn-site.xml</p><p>&lt;!– 指定YARN的老大（ResourceManager）的地址 –&gt;</p><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;hadoop01&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><blockquote><p>  &lt;!– reducer获取数据的方式 –&gt;</p></blockquote><blockquote><p>  &lt;property&gt;</p></blockquote><blockquote><p>  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</p></blockquote><blockquote><p>  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</p></blockquote><blockquote><p>  &lt;/property&gt;</p></blockquote><p>第六步：如果配置分布式需要修改slaves文件</p><p>#vi slaves</p><p>将需要启动的datanode机器名添加</p><p>hadoop01</p><p>hadoop02</p><p>hadoop03</p><p>第七步：分发到hadoop02 hadoop03</p><p>#scp -r /usr/local/hadoop hadoop02:/usr/local/</p><p>#scp -r /usr/local/hadoop hadoop03:/usr/local/</p><h1 id="八：-启动运行Hadoop2-7-1"><a href="#八：-启动运行Hadoop2-7-1" class="headerlink" title="八： 启动运行Hadoop2.7.1"></a>八： 启动运行Hadoop2.7.1</h1><h3 id="1、格式化namenode（是对namenode进行初始化）"><a href="#1、格式化namenode（是对namenode进行初始化）" class="headerlink" title="1、格式化namenode（是对namenode进行初始化）"></a>1、格式化namenode（是对namenode进行初始化）</h3><p>#hdfs namenode -format</p><blockquote><p>  或执行</p></blockquote><p>#hadoop namenode -format</p><h3 id="2、启动hadoop"><a href="#2、启动hadoop" class="headerlink" title="2、启动hadoop"></a>2、启动hadoop</h3><p>先启动HDFS</p><p>#cd /usr/local/hadoop</p><p>#sbin/start-dfs.sh</p><p>再启动YARN</p><p>#sbin/start-yarn.sh</p><h3 id="3、验证是否启动成功"><a href="#3、验证是否启动成功" class="headerlink" title="3、验证是否启动成功"></a>3、验证是否启动成功</h3><p>使用jps命令验证，前面的数字为进程PID，每次的进程号可能不同。如果要停止某个进程可以用kill<br>-9 PID</p><p>#jps</p><blockquote><p>  27408 NameNode</p></blockquote><blockquote><p>  28218 Jps</p></blockquote><blockquote><p>  27643 SecondaryNameNode</p></blockquote><blockquote><p>  28066 NodeManager</p></blockquote><blockquote><p>  27803 ResourceManager</p></blockquote><blockquote><p>  27512 DataNode</p></blockquote><h3 id="4、打开浏览器，输入网址，如果打不开可以查看linux的防火墙是否关闭。"><a href="#4、打开浏览器，输入网址，如果打不开可以查看linux的防火墙是否关闭。" class="headerlink" title="4、打开浏览器，输入网址，如果打不开可以查看linux的防火墙是否关闭。"></a>4、打开浏览器，输入网址，如果打不开可以查看linux的防火墙是否关闭。</h3><blockquote><p>  <a href="http://hadoop01:50070" target="_blank" rel="noopener">http://hadoop01:50070</a> （HDFS管理界面）</p></blockquote><blockquote><p>  <a href="http://hadoop01:8088" target="_blank" rel="noopener">http://hadoop01:8088</a> （MR管理界面）</p></blockquote><h3 id="5、查看运行状态："><a href="#5、查看运行状态：" class="headerlink" title="5、查看运行状态："></a>5、查看运行状态：</h3><p>#hdfs dfsadmin -report</p><h1 id="九：-HDFS命令"><a href="#九：-HDFS命令" class="headerlink" title="九： HDFS命令"></a>九： HDFS命令</h1><h3 id="1、HDFS工作机制"><a href="#1、HDFS工作机制" class="headerlink" title="1、HDFS工作机制"></a>1、HDFS工作机制</h3><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image160.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image162.png" alt></p><h3 id="2、HFDS命令行操作基本语法"><a href="#2、HFDS命令行操作基本语法" class="headerlink" title="2、HFDS命令行操作基本语法"></a>2、HFDS命令行操作基本语法</h3><p>bin/hdfs dfs 具体命令</p><p>或 hdfs dfs 具体命令，建议使用hdfs dfs</p><h3 id="3、参数大全"><a href="#3、参数大全" class="headerlink" title="3、参数大全"></a>3、参数大全</h3><p>bin/hdfs dfs</p><table><thead><tr><th>-help 功能：输出这个命令参数手册</th></tr></thead><tbody><tr><td><strong>-ls</strong>  <strong>功能：显示目录信息</strong> 示例： hdfs dfs -ls hdfs://hadoop-server01:9000/ 备注：这些参数中，所有的hdfs路径都可以简写 –&gt;hdfs dfs -ls / 等同于上一条命令的效果</td></tr><tr><td><strong>-mkdir</strong>  <strong>功能：在hdfs上创建目录</strong> 示例：hdfs dfs -mkdir -p /aaa/bbb/cc/dd</td></tr><tr><td><strong>-moveFromLocal</strong>  <strong>功能：从本地剪切粘贴到hdfs</strong> 示例：hdfs dfs - moveFromLocal /home/hadoop/a.txt /aaa/bbb/cc/dd <strong>-moveToLocal</strong>  <strong>功能：从hdfs剪切粘贴到本地</strong> 示例：hdfs dfs - moveToLocal /aaa/bbb/cc/dd /home/hadoop/a.txt</td></tr><tr><td><strong>–appendToFile</strong>  <strong>功能：追加一个文件到已经存在的文件末尾</strong> 示例：hdfs dfs -appendToFile ./hello.txt hdfs://hadoop-server01:9000/hello.txt 可以简写为： Hdfs dfs -appendToFile ./hello.txt /hello.txt</td></tr><tr><td><strong>-cat</strong>  <strong>功能：显示文件内容</strong>  示例：hdfs dfs -cat /hello.txt <strong>-tail</strong>  <strong>功能：显示一个文件的末尾</strong> 示例：hdfs dfs -tail /weblog/access_log.1 <strong>-text</strong>  <strong>功能：以字符形式打印一个文件的内容</strong> 示例：hdfs dfs -text /weblog/access_log.1</td></tr><tr><td><strong>-chgrp</strong>  <strong>-chmod -chown 功能：linux文件系统中的用法一样，对文件所属权限</strong> 示例： hdfs dfs -chmod 666 /hello.txt hdfs dfs -chown someuser:somegrp /hello.txt</td></tr><tr><td><strong>-copyFromLocal</strong>  <strong>功能：从本地文件系统中拷贝文件到hdfs路径去</strong> 示例：hdfs dfs -copyFromLocal ./jdk.tar.gz /aaa/ <strong>-copyToLocal</strong>  <strong>功能：从hdfs拷贝到本地</strong> 示例：hdfs dfs -copyToLocal /aaa/jdk.tar.gz</td></tr><tr><td><strong>-cp</strong>  <strong>功能：从hdfs的一个路径拷贝hdfs的另一个路径</strong> 示例： hdfs dfs -cp /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2 <strong>-mv</strong>  <strong>功能：在hdfs目录中移动文件</strong> 示例： hdfs dfs -mv /aaa/jdk.tar.gz /</td></tr><tr><td><strong>-get</strong>  <strong>功能：等同于copyToLocal，就是从hdfs下载文件到本地</strong> 示例：hdfs dfs -get /aaa/jdk.tar.gz <strong>-getmerge</strong>  <strong>功能：合并下载多个文件</strong> 示例：比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,… hdfs dfs -getmerge /aaa/log.* ./log.sum</td></tr><tr><td><strong>-put</strong>  <strong>功能：等同于copyFromLocal</strong> 示例：hdfs dfs -put /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2</td></tr><tr><td><strong>-rm</strong>  <strong>功能：删除文件或文件夹</strong> 示例：hdfs dfs -rm -r /aaa/bbb/ <strong>-rmdir</strong>  <strong>功能：删除空目录</strong> 示例：hdfs dfs -rmdir /aaa/bbb/ccc</td></tr><tr><td><strong>-df</strong>  <strong>功能：统计文件系统的可用空间信息</strong> 示例：hdfs dfs -df -h / <strong>-du</strong>  <strong>功能：统计文件夹的大小信息</strong> 示例： hdfs dfs -du -s -h /aaa/*</td></tr><tr><td><strong>-count</strong>  <strong>功能：统计一个指定目录下的文件节点数量</strong> 示例：hdfs dfs -count /aaa/</td></tr><tr><td><strong>-setrep</strong>  <strong>功能：设置hdfs中文件的副本数量</strong> 示例：hdfs dfs -setrep 3 /aaa/jdk.tar.gz &lt;这里设置的副本数只是记录在namenode的元数据中，是否真的会有这么多副本，还得看datanode的数量&gt;</td></tr></tbody></table><h3 id="4、常用命令举例"><a href="#4、常用命令举例" class="headerlink" title="4、常用命令举例"></a>4、常用命令举例</h3><p>（1）-help：输出这个命令参数</p><p>#hdfs dfs -help rm</p><p>（2）-ls: 显示目录信息</p><p># hdfs dfs -ls /</p><p>（3）-mkdir：在hdfs上创建目录</p><p># hdfs dfs -mkdir -p /aaa/bbb/cc/dd</p><p>（4）-rm：删除文件或文件夹</p><p># hdfs dfs -rm -r /aaa/bbb/</p><p>（5）-rmdir：删除空目录</p><p># hdfs dfs -rmdir /aaa/bbb/ccc</p><p>（6）-get：从hdfs复制到本地Linux</p><p># hdfs dfs - get /aaa/bbb/cc/dd /home/hadoop/a.txt</p><p>（7）-put：从Linux复制到hadoop等同于copyFromLocal</p><p># hdfs dfs -put /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2</p><p>（8）-cat ：显示文件内容</p><p># hdfs dfs - cat /home/hadoop/a.txt</p><p>（9）-cp ：从hdfs的一个路径拷贝到hdfs的另一个路径</p><p>#hdfs dfs -cp /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2</p><p>（10）-mv：在hdfs目录中移动文件</p><p># hdfs dfs -mv /aaa/jdk.tar.gz /</p><h1 id="十：-运行Mapreduce程序"><a href="#十：-运行Mapreduce程序" class="headerlink" title="十： 运行Mapreduce程序"></a>十： 运行Mapreduce程序</h1><h3 id="1、MapReduce核心思想"><a href="#1、MapReduce核心思想" class="headerlink" title="1、MapReduce核心思想"></a>1、MapReduce核心思想</h3><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image164.jpg" alt></p><p>上图简单的阐明了map和reduce的两个过程或者作用，虽然不够严谨，但是足以提供一个大概的认知，map过程是一个蔬菜到制成食物前的准备工作，reduce将准备好的材料合并进而制作出食物的过程</p><p>1）分布式的运算程序往往需要分成至少2个阶段；</p><p>2）第一个阶段的maptask并发实例，完全并行运行，互不相干；</p><p>3）第二个阶段的reduce<br>task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出；</p><p>4）MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行；</p><h3 id="2、mapreduce案例"><a href="#2、mapreduce案例" class="headerlink" title="2、mapreduce案例"></a>2、mapreduce案例</h3><h4 id="生成要统计的文本"><a href="#生成要统计的文本" class="headerlink" title="生成要统计的文本"></a>生成要统计的文本</h4><p>#vi test.txt</p><table><thead><tr><th>Hello tom Hello jim Hello ketty Hello world Ketty tom</th></tr></thead></table><h4 id="在hdfs上创建输入数据文件夹"><a href="#在hdfs上创建输入数据文件夹" class="headerlink" title="在hdfs上创建输入数据文件夹"></a>在hdfs上创建输入数据文件夹</h4><p>#hadoop fs mkdir -p /wordcount/input</p><h4 id="将test-txt上传到hdfs上"><a href="#将test-txt上传到hdfs上" class="headerlink" title="将test.txt上传到hdfs上"></a>将test.txt上传到hdfs上</h4><p>#hdfs dfs –put /root/test.txt /wordcount/input</p><h4 id="运行一个mapreduce程序"><a href="#运行一个mapreduce程序" class="headerlink" title="运行一个mapreduce程序"></a>运行一个mapreduce程序</h4><p>在HADOOP安装目录下，运行一个示例mr程序</p><p># cd /usr/local/hadoop/share/hadoop/mapreduce/</p><p># hadoop jar hadoop-mapreduce-examples-2.7.1.jar wordcount /wordcount/input<br>/wordcount/output</p><p>以下是运行的截屏</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image168.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image170.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image172.png" alt></p><h4 id="查看运行结果"><a href="#查看运行结果" class="headerlink" title="查看运行结果"></a>查看运行结果</h4><p># hdfs dfs -ls /wordcount/output</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image174.png" alt></p><p># hdfs dfs -cat /wordcount/output/part-r-00000</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image176.png" alt><br>也可以在浏览器中查看</p><p><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image178.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image180.png" alt><br><img src="/2020/03/29/hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/image182.png" alt></p><p>选择Download下载后查看。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【转载】github下载慢问题解决</title>
      <link href="/2020/03/28/github%E4%B8%8B%E8%BD%BD%E6%85%A2/"/>
      <url>/2020/03/28/github%E4%B8%8B%E8%BD%BD%E6%85%A2/</url>
      
        <content type="html"><![CDATA[<p><font color="blue"><strong><a href="https://blog.csdn.net/a1439775520/article/details/105155813" target="_blank" rel="noopener">阅读原文</a></strong></font></p><blockquote><p>通过码云来导入github，通过码云下载</p></blockquote><p>第一步：<br><strong>找一个你需要下载的GitHub项目</strong><a id="more"></a><img src="https://img-blog.csdnimg.cn/20200328093031557.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>第二步：<br>复制链接</strong><br><img src="https://img-blog.csdnimg.cn/20200328093109637.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>第三步：<br>打开码云，然后选择从GitHub导入</strong><br><img src="https://img-blog.csdnimg.cn/20200328093143714.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>第四步：<br>复制刚才的连接，起个名字，点击导入</strong><br><img src="https://img-blog.csdnimg.cn/20200328093223266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>这个过程大概一两分钟</strong><br><img src="https://img-blog.csdnimg.cn/20200328093315682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>导入完成：直接下载zip<br><img src="https://img-blog.csdnimg.cn/20200328093348780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>一个完整的过程动图<br><img src="https://img-blog.csdnimg.cn/20200328094952899.gif" alt="在这里插入图片描述"><br>原文链接：<a href="https://blog.csdn.net/a1439775520/article/details/105155813" target="_blank" rel="noopener">https://blog.csdn.net/a1439775520/article/details/105155813</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搭建一个hexo+github博客的方法</title>
      <link href="/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p> <strong>2020/3/27，自己的Hexo博客总算run起来了，算上优化主题，来来回回花费了三天时间才弄好，下面来分享一下搭建一个hexo博客的方法。</strong></p><h1 id="01-安装-Node-js"><a href="#01-安装-Node-js" class="headerlink" title="01.安装 Node.js"></a>01.安装 Node.js</h1><p>=====================================</p><p>打开<a href="https://nodejs.org" target="_blank" rel="noopener">官方网站</a><br><code>https://nodejs.org</code>  </p><a id="more"></a><p><img src="/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/1.png" alt><br>安装步骤非常简单，一直next，下一步就可以了，默认安装就行。</p><h1 id="02-安装-Git"><a href="#02-安装-Git" class="headerlink" title="02.安装 Git"></a>02.安装 Git</h1><p>===================================</p><p>打开<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">官方网站</a><br><code>https://git-scm.com/downloads</code><br>然后我们选择windows版本的下载<br><img src="/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/2.png" alt><br>安装也是一直点下一步，安装官方默认的来就行，<br>完了，在开始菜单可以看到<br><img src="/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/4.png" alt>  </p><blockquote><p>  安装完Git别忘了配置环境变量！</p></blockquote><blockquote><p>tips：这个Git Bash下载下来就相当于Linux中的终端窗口了，以后我们就用这个东西来打开终端。</p></blockquote><h1 id="03-安装hexo"><a href="#03-安装hexo" class="headerlink" title="03.安装hexo"></a>03.安装hexo</h1><p>===================================</p><p>先在终端输入node -v  和  npm -v（若出现版本号则安装成功）</p><p>看看 ==node，npm== 是否安装成功，没有成功的就重新安装node。</p><p><strong>我们需要先来安装个cnpm提高速度，以后下载什么东西都用cnpm</strong></p><p>在上面终端继续输入<br><code>npm install -g cnpm --registry=https://registry.npm.taobao.org</code><br>下载完后继续输入 cnpm -v验证是否安装成功</p><p>==完成之后安装hexo==<br><code>cnpm install -g hexo-cli</code></p><p>==验证是否安装成功==<br><code>hexo -v</code><br>出现,说明成功  </p><p>我们可以在想要保存博客的地方创建文件夹（mkdir blog)</p><p>然后我们运行下面命令，这步是关键，主要是建立整个项目。<br><code>hexo init</code><br>之后打开blog目录如下：<br><img src="/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/6.jpg" alt>  </p><h1 id="04-运行测试"><a href="#04-运行测试" class="headerlink" title="04.运行测试"></a>04.运行测试</h1><p>=============================</p><p>这里我们经常用到的有三个命令  </p><p><code>1.hexo clean #用来清理缓存文件</code><br><code>2.hexo g      #部署文件</code><br><code>3 hexo  s     #运行本地服务器</code><br><code>4  hexo  d   #上传到服务器</code> </p><p>我们运行<br><code>hexo s</code>  </p><p>打开浏览器，输入<code>localhost:4000</code>,看到  </p><p><img src="/2020/03/27/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/5.png" alt></p><p><strong>说明本地环境搭建已完成</strong></p><h1 id="05-把博客部署到github上"><a href="#05-把博客部署到github上" class="headerlink" title="05.把博客部署到github上"></a>05.把博客部署到github上</h1><p>=====================================<br>首先我们登录github官网，注册，登录，新建一个数据库，数据库名称必须和自己账号昵称一样：xxx.github.io<br><code>这个数据库名字就是以后我们访问博客的链接。</code></p><h1 id="06-配置-config-yml-文件"><a href="#06-配置-config-yml-文件" class="headerlink" title="06.配置_config.yml 文件"></a>06.配置_config.yml 文件</h1><p>=====================================<br>打开该文件，翻到最后<br>在最后加上下面三个属性<br> ==type: ‘git’<br>  repo: <a href="https://github.com/haoyujie001/haoyujie001.github.io.git" target="_blank" rel="noopener">https://github.com/haoyujie001/haoyujie001.github.io.git</a><br>  branch: master==<br> <code>注意每个冒号后面有一个空格</code></p><h1 id="07-上传到服务器"><a href="#07-上传到服务器" class="headerlink" title="07.上传到服务器"></a>07.上传到服务器</h1><p>=====================================<br>终端输入hexo d<br>然后输入你的github账号密码<br>会提示推送成功<br>==输入时密码是不会显示的哦==<br>然后刷新你的GitHub数据库会发现多了很多文件<br><strong>之后我们就可以复制仓库名字来访问我们的博客了</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/03/24/hello-world/"/>
      <url>/2020/03/24/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
